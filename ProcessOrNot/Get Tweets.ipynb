{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Getting the Tweets\n",
    "\n",
    "In this notebook I use the Tweets class to get the tweets using the Tweepy package by their id. These texts will be\n",
    "either fully processed by the ```preProcess``` or not. Any non english tweets will be translated using the google cloud api."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ProcessOrNot.Twitter import Tweets\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from decouple import config\n",
    "\n",
    "# the .env file must be placed in the root of the project\n",
    "tweets = Tweets(config('TWITTER_API_KEY'),\n",
    "               config('TWITTER_API_SECRET'),\n",
    "               config('TWITTER_ACCESS_TOKEN_KEY'),\n",
    "               config('TWITTER_ACCESS_TOKEN_SECRET'),\n",
    "               '../service_account.json')\n",
    "# the language set collected at this stage\n",
    "languages = {\n",
    "                1: 'en',\n",
    "                2: 'es',\n",
    "                3: 'fr',\n",
    "                4: 'de',\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Method\n",
    "\n",
    "In the below loop the 3 files in the Data/FilteredTwitterIDs are loaded. The feature we are interested in is the id feature.\n",
    "We know for sure that for every file there are 1000 tweets for each language.\n",
    "\n",
    "The next step is to use the ```addTweets``` function to get the tweets by their id. Since the ```statuses_lookup``` function\n",
    "only takes a maximum of a 100 ids at a time, the ```ids``` list of ids is sliced into 10, 100 sized lists using the\n",
    "```((j-1)*1000)+(k-1)*100:((j-1)*1000)+k*100``` slice.\n",
    "\n",
    "Due to the nature of the Tweets class, a temporary file needs to be saved before translation as this would change the\n",
    "data inside the object.\n",
    "\n",
    "After the not processed data is translated and saved, the temp file (not translated raw tweet data) is re loaded,\n",
    "pre-processed, translated and saved."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68e91f837bf1479996ddc0622a8fe294"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a83ffe87beaa4b949a3b12942aebb86b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "282e93c79faa4eb7a3eb139499928069"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09dc79adf0704366a399e6e2e2cfd3b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm([0,1,2]):\n",
    "    df = pd.read_csv('Data/FilteredTwitterIDs/' + str(i) + '.csv')\n",
    "    ids = df.tweet_id.values.tolist()\n",
    "    for j in tqdm(languages):\n",
    "        for k in range(1,11):\n",
    "            tweets.addTweets(ids[((j-1)*1000)+(k-1)*100:((j-1)*1000)+k*100])\n",
    "        tweets.saveJSON('Data/Text/temp')\n",
    "        if j != 1:\n",
    "            tweets.translate(language=languages[j])\n",
    "        tweets.saveJSON('Data/Text/NotProcessed/' + str(i) + str(j))\n",
    "        tweets.reset()\n",
    "        tweets.loadJSON('Data/Text/temp')\n",
    "        tweets.preProcess(languages[j])\n",
    "        if j != 1:\n",
    "            tweets.translate(language=languages[j])\n",
    "        tweets.saveJSON('Data/Text/Processed/' + str(i) + str(j))\n",
    "        tweets.reset()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}