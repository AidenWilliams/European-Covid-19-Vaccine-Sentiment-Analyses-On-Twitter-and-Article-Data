{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Getting the Tweets\n",
    "\n",
    "In this notebook I use the Tweets class to get the tweets using the Tweepy package by their id. These texts will be\n",
    "either fully processed by the ```preProcess``` or not. Any non english tweets will be translated using the google cloud api."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from Tweets import Tweets\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from decouple import config\n",
    "import os\n",
    "\n",
    "tweets = Tweets(   config('TWITTER_API_KEY'),\n",
    "                   config('TWITTER_API_SECRET'),\n",
    "                   config('TWITTER_ACCESS_TOKEN_KEY'),\n",
    "                   config('TWITTER_ACCESS_TOKEN_SECRET'),\n",
    "                   'service_account.json')\n",
    "\n",
    "languages = {\n",
    "                1: 'en',\n",
    "                2: 'es',\n",
    "                3: 'fr',\n",
    "                4: 'de',\n",
    "                5: 'nl',\n",
    "                6: 'it',\n",
    "            }\n",
    "\n",
    "months = ['December', 'January', 'February', 'March', 'April', 'May']"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Method\n",
    "\n",
    "In the below loop the 3 files in the Data/FilteredTwitterIDs are loaded. The feature we are interested in is the id feature.\n",
    "We know for sure that for every file there are 1000 tweets for each language.\n",
    "\n",
    "The next step is to use the ```addTweets``` function to get the tweets by their id. Since the ```statuses_lookup``` function\n",
    "only takes a maximum of a 100 ids at a time, the ```ids``` list of ids is sliced into 10, 100 sized lists using the\n",
    "```((j-1)*1000)+(k-1)*100:((j-1)*1000)+k*100``` slice.\n",
    "\n",
    "As the data will be pre-processed there is no need to store a copy of the un processed tweet data.\n",
    "\n",
    "Each set of tweets is preprocessed, translated and saved for future use."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/6 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "339a9d0ca6bb4369b293d48cc2c8e76b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61a457024a5c43b5b993910e608a7c68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a3dd39fb2a8425c8b0670a2dacecb20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cdc6e2eb77c745eeb1dd795e332dc588"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6929dddf070841949addc968e110d25e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30b69c7599c6455aadf97b9fc98717bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53cc6b6d7ce446ff805effe1be40f32e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for month in tqdm(months):\n",
    "    for day in tqdm([0, 1, 2, 3, 4]):\n",
    "        df = pd.read_json('Data/FilteredTwitterIDs/' + str(month) + str(day) + '.json')\n",
    "        ids = df.tweet_id.values.tolist()\n",
    "        for j in languages:\n",
    "            if os.path.isfile('Data/Text/' + str(month) + str(day) + languages[j] + '.json'):\n",
    "                continue\n",
    "            for k in range(1,11):\n",
    "                tweets.addTweets(ids[((j-1)*1000)+(k-1)*100:((j-1)*1000)+k*100])\n",
    "            tweets.preProcess(languages[j])\n",
    "            if j != 1:\n",
    "                tweets.translate(language=languages[j])\n",
    "            tweets.saveJSON('Data/Text/' + str(month) + str(day) + languages[j])\n",
    "            tweets.reset()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}